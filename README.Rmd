---
output: github_document
---

```{r, echo = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  message = FALSE,
  warning = FALSE,
  comment = "#>",
  # cache.path = "man/README",
  fig.path = "man/README/README-"
)
```

```{r eval = FALSE, echo = FALSE}
viz_void <- ggplot2::ggplot() + ggplot2::theme_void()

dir_logo <- file.path("man", "figures")
if(!exists(dir_logo)) {
  dir.create(dir_logo, recursive = TRUE)
}
filepath_logo <- file.path("man", "figures", paste0("logo.png"))
hexSticker::sticker(
  subplot = viz_void,
  package = "tetext",
  filename = file.path("man", "figures", paste0("logo.png")),
  p_y = 1.0,
  p_color = "black",
  # p_family = "sans",
  p_size = 40,
  h_size = 1.5,
  h_color = "black",
  h_fill = "yellow"
)
logo <- magick::image_read(filepath_logo)
magick::image_write(magick::image_scale(logo, "120"), path = filepath_logo)
```

# temisc <img src="man/figures/logo.png" align="right"/>

##  Introduction

This package containts functions that I often use.

### Installation

`devtools::install_github("tonyelhabr/temisc")`.

## Notes

Here is a list of all functions in the package.

```{r echo = FALSE}
# library("tetext")
# ls("package:tetext")
```

```{r include = FALSE}
# sprintf("Code coverage: %f", covr::package_coverage())
```

Here are some short descriptions. Functions are listed in order of
recommended use in a script.

+ __time:__ `visualize_time()`, `visualize_time_multi()`, `visualize_time_batched()`: 
Visualize data over time.
+ __tidify:__ `tidify_to_unigrams()`, `tidify_to_bigrams()`: 
Tokenize data to tidy format with unigrams/bigrams.
+ __cnts:__ `visualize_cnts()`, `visualize_cnts_multi()`, 
`visualize_cnts_wordcloud()`, `visualize_cnts_wordcloud_multi()`: Visualize counts of n-grams.
+ __freqs:__ `compute_freqs()`, `compute_freqs_multi()`,`visualize_bigrams_freqs_multi()`: 
Compute and visualize frequencies of n-grams.
+ __corrs:__ `compute_corrs()`, `visualize_corrs_network()`: 
Compute and visualize pairwise correlations (of bigrams).
+ __tfidf:__ `compute_tfidf()`, `visualize_tfidf_multi()`: 
Compute and visualize change in n-gram usage across documents.
+ __change:__ `compute_change()`, `visualize_change()`: 
Compute and visualize change in n-gram usage across documents.

### To Add?

#### In Progress

+ `get_xy_grid()`, `filter_xy_grid()`, `preprocess_xy_data()`, `postprocess_xy_data()`, `wrapper_func()`, `add_dummy_cols()`:
See the functions with the same names in my `tetweets` project.

#### Somewhat Likely

+ `model_lda()`, `visualize_lda_betas()`, `visualize_lda_gammas()`

#### Low Priority

+ `compute_freqs_wide()`: See `compute_unigrams_freqs()` in my `tetweets` project.
Then create `compute_freqs_wide_multi()` using `wrapper_funct()`.
+ `compute_logratios()`: See the function with the same name in my `tetweets` project.
Then create `compute_logratios_multi()`using `wrapper_funct()`.
+ `create_sents_ratios_wide()`, `visualize_sents_ratios()`: See the functions with the same names in my `tetweets` project.

#### Very Unlikely
+ ~~`compute_sentdiff_poisson()`, `prepare_sents_diffs_poisson()`, `visualize_sents_diffs_poission()`~~

## Examples

```{r echo = FALSE}
# library("tetext")
```
