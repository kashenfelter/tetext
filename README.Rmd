---
output: github_document
---

```{r, echo = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  message = FALSE,
  warning = FALSE,
  comment = "#>",
  # cache.path = "man/README",
  fig.path = "man/README/README-"
)
```

```{r eval = FALSE, echo = FALSE}
viz_void <- ggplot2::ggplot() + ggplot2::theme_void()

dir_logo <- file.path("man", "figures")
if(!exists(dir_logo)) {
  dir.create(dir_logo, recursive = TRUE)
}
filepath_logo <- file.path("man", "figures", paste0("logo.png"))
hexSticker::sticker(
  subplot = viz_void,
  package = "tetext",
  filename = file.path("man", "figures", paste0("logo.png")),
  p_y = 1.0,
  p_color = "black",
  # p_family = "sans",
  p_size = 40,
  h_size = 1.5,
  h_color = "black",
  h_fill = "yellow"
)
logo <- magick::image_read(filepath_logo)
magick::image_write(magick::image_scale(logo, "120"), path = filepath_logo)
```

# temisc <img src="man/figures/logo.png" align="right"/>

##  Introduction

This package containts functions that I often use.

### Installation

`devtools::install_github("tonyelhabr/temisc")`.

## Notes

### Inspiration

This package is heavily influenced by the blogs of
[David Robinson](http://varianceexplained.org/posts/) and 
[Julia Silge](juliasilge.com/blog/), as well as their co-authored book
[_Text Mining with R_](https://www.tidytextmining.com/).
Most of the functions in this package implement snippets of code that they have
shared.

### Syntax

This package follows the `dplyr` convention of suffixing standard evaluation (SE)
function with `_at`. These functions expect characters (as inputs) to indicate
column names. 

There are non-suffixed versions of all major functions that serve as aliases to the `_at` SE functions. 
In the future, if non-standard evaluation (NSE) is implemented,
the non-suffixed versions will be altered to refer to the NSE versions.
(This would comply with the `dplyr` convetion for NSE functions)

Here is a list of all functions in the package.

```{r echo = FALSE}
# library("tetext")
# ls("package:tetext")
```

```{r include = FALSE}
# sprintf("Code coverage: %f", covr::package_coverage())
```

Here are some short descriptions of the functions, grouped generally
by usage. Functions are listed in order of
recommended use in a script (and in the order in which I wrote them).

+ __time:__ `visualize_time_at()`, `visualize_time_multi_at()`, `visualize_time_batch()`: 
Visualize data over time.
+ __tidify:__ `tidify_to_unigrams_at()`, `tidify_to_bigrams_at()`: 
Tokenize data to tidy format with unigrams or bigrams.
+ __cnts:__ `visualize_cnts_at()`, `visualize_cnts_multi_at()`, 
`visualize_cnts_wordcloud_at()`, `visualize_cnts_wordcloud_multi_at()`: Visualize counts of n-grams.
+ __freqs:__ `compute_freqs_at()`, `compute_freqs_multi_at()`,
`visualize_bigrams_freqs_multi_at()`, `compute_freqs_multi_by2_at()`,
`visualize_freqs_multi_by2_at()`: 
Compute and visualize frequencies of n-grams.
+ __corrs:__ `compute_corrs_at()`, `visualize_corrs_network_at()`: 
Compute and visualize pairwise correlations (of bigrams).
+ __tfidf:__ `compute_tfidf_at()`, `visualize_tfidf_at()`: 
Compute and visualize change in n-gram usage across documents.
+ __change:__ `compute_change_at()`, `visualize_change_at()`: 
Compute and visualize change in n-gram usage across documents.
+ __sents:__ `compute_sent_summary_at()`, `compute_sent_summary_multi_at()`
Compute sentiment scores for n-grams.
+ __xy:__ `compute_freqs_multi_by2_at()`, `visualize_freqs_multi_by2_at()`, 
`compute_logratios_multi_by2_at()`, `visualize_logratios_multi_by2_at()`,
`compute_sentratios_multi_by2_at()`, `visualize_sentratios_multi_by2_at()`,
Compute metrics across multiple `multi` entities. Uses a handful of internal
function that are not intended to be called directly (although they can be).
These internal functions include  the following:
`create_xy_grid()`, `filter_xy_grid()`, `preprocess_xy_data()`, `postprocess_xy_data()`, 
`wrapper_func()`, `add_dummy_cols()`.
Also, there are more specific internal functions, such as:
`compute_freqs_multi_wide_at()`, `compute_logratios_multi_wide_at()`, `compute_sentratios_multi_wide_at()`

### Notes To Self

#### TODO

Add `lab_caption` for visualization functions.

+ ~~__model:__~~ `model_lda()`, `visualize_lda_betas()`, `visualize_lda_gammas()`
+ ~~__poisson:__~~
`compute_sentdiff_poisson()`, `prepare_sents_diffs_poisson()`, `visualize_sents_diffs_poission()`

## Examples

For now, see the tests.

```{r echo = FALSE}
# library("tetext")
```
